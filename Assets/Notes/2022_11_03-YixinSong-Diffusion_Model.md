# Diffusion Model æ‰©æ•£æ¨¡å‹

==ğŸ˜ Edited at 2022-11-04 by **Song1xinn**==

## 1. Introduce

### 1.1 DALLÂ·E 2

> DALLÂ·E2ï¼šhttps://openai.com/dall-e-2/	DALLÂ·E miniï¼šhttps://huggingface.co/spaces/dalle-mini/dalle-mini	Imagen / Parti - Google

==DALLÂ·E 2==   CLIP + diffusion model

<img src="imgs/2022_11_03-YixinSong-Diffusion_Model.assets/unCLIP.png" alt="img" style="zoom: 25%;" />

==CLIP==  

> 1ï¸âƒ£CLIP pre-trains an image encoder and a text encoder to predict which images were paired with which texts in our dataset.  2ï¸âƒ£Then use this behavior to turn CLIP into a **zero-shot** **classifier**.  3ï¸âƒ£Convert all of a datasetâ€™s classes into captions such as â€œa photo of a *dog*â€ and **predict the class of the caption** with a given image.

<img src="imgs/2022_11_03-YixinSong-Diffusion_Model.assets/image-20221028102512738.png" alt="image-20221028102512738" style="zoom:40%;" />

### 1.2 Generation Models

<img src="imgs/2022_11_03-YixinSong-Diffusion_Model.assets/generative-overview.png" alt="img" style="zoom: 20%;" />



## 2. What's Diffusion Model

å‰æï¼šæ‰€æœ‰çš„å›¾åƒéƒ½æ»¡è¶³è‡ªç„¶ä¸­çš„åˆ†å¸ƒï¼ˆdistributionï¼‰ï¼Œæ¯”å¦‚æ‰€æœ‰å¸¦æœ‰å°çŒ«çš„å›¾éƒ½éµå¾ªä¸€ç§åˆ†å¸ƒã€æ‰€æœ‰å¸¦æœ‰å°ç‹—çš„å›¾éƒ½éµå¾ªä¸€ç§åˆ†å¸ƒã€‚

### 2.1 Forward diffusion processï¼ˆTraining Process ONLYï¼‰

> Given a data point sampled from a real data distribution $ x_0âˆ¼q(x)$, let us define a ***forward diffusion process*** in which we add small amount of **Gaussian noise** to the sample in $T$ steps, producing a sequence of noisy samples $x_1,â€¦,x_T$.  The data sample $ x_0$ gradually loses its distinguishable features as the step $t$ becomes larger. Eventually when $ Tâ†’âˆ$, $x_T $ is equivalent to an isotropic Gaussian distribution.

<img src="imgs/2022_11_03-YixinSong-Diffusion_Model.assets/image-20221028154018397.png" alt="image-20221028154018397" style="zoom: 50%;" />

**ç›®æ ‡ï¼š** $q(x_T|x_0)$

ç»™å®šå¦‚ä¸‹å…¬å¼ï¼Œå…¶ä¸­ $ {Î²_tâˆˆ(0,1)}_{t=1}^T$ï¼Œå¯ä»¥ç†è§£ä¸ºæ·»åŠ çš„å™ªå£°çš„å æ¯”ï¼Œæ˜¯è‡ªå®šçš„å‡½æ•°ï¼Œæ‰€ä»¥å¯ä»¥çœ‹ä½œå·²çŸ¥é‡ã€‚
$$
\alpha_t = 1-\beta_t
$$

é‚£ä¹ˆï¼Œå¦‚æœå·²çŸ¥ $x_{t-1}$ ï¼Œæˆ‘ä»¬è®¾å®š $x_t$ ä¸ºä¸‹è¿°å…¬å¼ï¼Œå…¶ä¸­ $\epsilon_t$ è¡¨ç¤ºæ—¶åˆ» $t$ åŠ çš„å™ªå£°ï¼š
$$
x_t = \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\epsilon_t\label{2}
$$
åŒç†ï¼Œ $x_{t-1}$ å¯ä»¥ç”± $x_{t-2}$ è¡¨ç¤ºï¼Œå†ç”±äºæ¯ä¸€æ¬¡æ·»åŠ å™ªå£°éƒ½æ˜¯ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·çš„å™ªå£°ï¼Œå³ $\epsilon_tâˆ¼N(0,\boldsymbol I)$ ï¼ŒåŸºäºæ­¤ï¼Œæˆ‘ä»¬è¿˜èƒ½æ¨ç†å¾—åˆ° $x_t$ ä¸ $x_{t-2}$ çš„å…³ç³»ï¼Œå…¶ä¸­ $\epsilon$ åˆå¹¶äº†ä¸¤ä¸ªé«˜æ–¯åˆ†å¸ƒï¼š
$$
x_{t} = \sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_{t-1}}\epsilon_{t-1})+ \sqrt{1-\alpha_t}\epsilon_t
\\ = \sqrt{\alpha_t}\sqrt{\alpha_{t-1}}x_{t-2} + \sqrt{\alpha_t}\sqrt{1-\alpha_{t-1}}\epsilon_{t-1}+ \sqrt{1-\alpha_t}\epsilon_t
\\ =\sqrt{\alpha_t\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_t\alpha_{t-1}} \epsilon
$$

> ==**æ•°å­¦è§£é‡Š**==
>
> * å…³äº $\epsilon_t$ çš„é«˜æ–¯åˆ†å¸ƒå¯ä»¥å†™ä½œï¼š$\epsilon_tâˆ¼N(0,\sigma_1^2)$ï¼Œä¹˜ä¸Š $ w$ åæ–¹å·®å˜ä¸º $\sigma_1^2 * w^2$ï¼ŒåŠ ä¸Š $b$ åå‡å€¼å˜ä¸º $0+b$ ã€‚
> * å¦‚æœä¸¤ä¸ªç›¸äº’ç‹¬ç«‹çš„é«˜æ–¯åˆ†å¸ƒ$\epsilon_1âˆ¼N(\mu_1,\sigma_1^2), \epsilon_2âˆ¼N(\mu_2,\sigma_2^2)$ï¼Œé‚£ä¹ˆ$\epsilon = (a\epsilon_1 Â± b\epsilon_2)âˆ¼N(a\mu_1Â±b\mu_2,a^2\sigma_1^2+b^2\sigma_2^2)$
> * ç°åœ¨æœ‰ä¸¤ä¸ªé«˜æ–¯åˆ†å¸ƒ ï¼š $\sqrt{\alpha_t(1-\alpha_{t-1})}\epsilon_{t-1}âˆ¼N(0,\alpha_t(1-\alpha_{t-1})) $ï¼Œ$\sqrt{1-\alpha_t}\epsilon_tâˆ¼N(0,1-\alpha_t) $
>   ä¸¤ä¸ªåˆ†å¸ƒç›¸åŠ å¯ä»¥å¾—åˆ°ï¼š$\sqrt{\alpha_t(1-\alpha_{t-1})}\epsilon_{t-1} + \sqrt{1-\alpha_t}\epsilon_t âˆ¼N(0,1-\alpha_t\alpha_{t-1})$ 

å¯ä»¥æ¨ç†å¾—åˆ° $x_t$ ä¸ $x_0$ çš„å…³ç³»ï¼Œå…¶ä¸­ $\bar\alpha_t$ è¡¨ç¤ºç´¯ä¹˜ï¼š
$$
x_{t} =\sqrt{\bar\alpha_t}x_{0} + \sqrt{1-\bar\alpha_t}\epsilon\label{4}
$$
==å›åˆ°æ¦‚ç‡åˆ†æ==  

ç»™å®šåˆå§‹çš„æ•°æ®åˆ†å¸ƒ $x_0 âˆ¼ q(x)$ï¼Œå¯ä»¥ä¸æ–­åœ°å‘åˆ†å¸ƒä¸­æ·»åŠ é«˜æ–¯å™ªå£°ï¼Œè¯¥å™ªå£°çš„æ–¹å·®ä»¥å›ºå®šå€¼ $\beta_t$ ç¡®å®šï¼Œå‡å€¼ä»¥ $\beta_t$ å’Œå½“å‰æ—¶åˆ» $t$ çš„æ•°æ® $x_t$ å†³å®šã€‚åŸºäºå‰ä¸€æ—¶åˆ»å»é¢„æµ‹åä¸€æ—¶åˆ»æ˜¯ä¸€ä¸ªæ¡ä»¶æ¦‚ç‡åˆ†å¸ƒï¼Œç»™å®š $x_0$ ï¼Œ $x_1$ åˆ° $x_T$ çš„è”åˆæ¦‚ç‡åˆ†å¸ƒå¯ä»¥å†™ä¸ºæ¡ä»¶æ¦‚ç‡åˆ†å¸ƒç›¸ä¹˜ï¼š
$$
q(x_{1:T}|x_{0}) = \prod^T_{t=1} q(x_t|x_{t-1}) \qquad q(x_t|x_{t-1}) = N(x_t; \sqrt{1-\beta_t}x_{t-1},\beta_t\boldsymbol I)\label{11}
$$
å…¬å¼ $\eqref{11}$ ä¸­å¯ä»¥çœ‹å‡ºè¿™ä¸ªåˆ†å¸ƒçš„å‡å€¼æ˜¯ $\sqrt{1-\beta_t}x_{t-1}$ ï¼Œæ–¹å·®æ˜¯ $\beta_t$ ï¼Œå¯ä»¥å¾—åˆ°ç”± $x_{t-1}$ è¡¨ç¤ºçš„ $x_t$ï¼Œä¹Ÿå°±æ˜¯å…¬å¼ $\eqref{2}$ ã€‚å’Œå‰é¢çš„æ¨ç†åŸç†ç›¸åŒï¼Œé€šè¿‡å¯¹é«˜æ–¯åˆ†å¸ƒçš„ç›¸åŠ ï¼Œå¾—åˆ° $x_t$ å…³äº $x_0$ çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚
$$
q(x_t|x_0) = N(x_t; \sqrt{\bar\alpha_t}x_0,(1-\bar\alpha_t)\boldsymbol I)
$$
éšç€ $t$ çš„ä¸æ–­å¢å¤§ï¼Œå½“ $T \to \infty  $ï¼Œæœ€ç»ˆæ•°æ®åˆ†å¸ƒ $x_T$ å˜æˆäº†ä¸€ä¸ªå„å‘ç‹¬ç«‹çš„é«˜æ–¯åˆ†å¸ƒã€‚
æ³¨æ„ï¼Œå‰å‘è¿‡ç¨‹ä¸åŒ…æ‹¬ä»»ä½•éœ€è¦å­¦ä¹ çš„å‚æ•°ã€‚

==ğŸ¤”Question==  **Why forward diffusion process ï¼Ÿ**

### 2.2 Reverse diffusion process

> if we can reverse the above process and sample from $q(x_{tâˆ’1}|x_t)$, we will be able to recreate the true sample from a Gaussian noise input, $x_Tâˆ¼N(0,I)$. Note that if $Î²_t$ is small enough, $q(x_{tâˆ’1}|x_t)$ will also be Gaussian. Unfortunately, we cannot easily estimate $q(x_{tâˆ’1}|x_t)$ because it needs to use the entire dataset and therefore we need to learn a **model $p_Î¸$** to approximate these conditional probabilities in order to run the *reverse diffusion process*.

<img src="imgs/2022_11_03-YixinSong-Diffusion_Model.assets/image-20221028201952767.png" alt="image-20221028201952767" style="zoom:55%;" />

<img src="imgs/2022_11_03-YixinSong-Diffusion_Model.assets/DDPM.png" alt="img" style="zoom: 15%;" />

**ç›®æ ‡ï¼š** $p_\theta(x_0|x_T)$

é€†è¿‡ç¨‹æ˜¯ä»é«˜æ–¯å™ªå£°ä¸­å›å¤åŸå§‹æ•°æ®ï¼Œæ‰€ä»¥å¯ä»¥å‡è®¾å…¶ä¹Ÿæ˜¯ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒï¼Œåœ¨è¿™é‡Œéœ€è¦æ„å»ºä¸€ä¸ªæ¨¡å‹ $p_\theta$ æ¥é€šè¿‡ç»™å®šçš„å™ªå£°æ¥é¢„æµ‹å‡ºè®­ç»ƒé›†çš„åˆ†å¸ƒï¼Œä»è€Œå¯ä»¥é€šè¿‡ä»åˆ†å¸ƒä¸­é‡‡æ ·æ¥ç”Ÿæˆæ–°çš„æ ·æœ¬ã€‚
$$
p_\theta(x_{0:T}) =p(x_T) \prod^T_{t=1} p_\theta(x_{t-1}|x_{t}) \qquad p_\theta(x_{t-1}|x_{t}) = N(x_{t-1}; \mu_\theta(x_t,t),\Sigma_\theta(x_t,t))\label{13}
$$
ç”±äºåå‘è¿‡ç¨‹æ²¡åŠæ³•ç›´æ¥æ±‚å¾— $x_0$ ä¸ $x_t$ ä¹‹é—´çš„å…³ç³»ï¼Œå³æ— æ³•ç›´æ¥ä»å™ªå£°åˆ°å›¾åƒï¼Œé‚£ä¹ˆæˆ‘ä»¬è½¬æ¢æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆæ±‚ $x_{t-1}$ï¼Œ$x_{t-2}$ ... ç›´åˆ°å¾—åˆ°$x_{0}$ï¼Œå³å…ˆæ±‚ $q(x_{t-1}|x_t)$ ï¼Œå†è¿›ä¸€æ­¥å»ºæ¨¡ã€‚è‹¥ç»™å®š $x_t, x_0$ åéªŒæ‰©æ•£æ¡ä»¶æ¦‚ç‡ $q(x_{t-1}|x_t,x_0) $åˆ†å¸ƒç”¨å…¬å¼è¡¨è¾¾ï¼š
$$
q(x_{t-1}|x_t,x_0)  = N(x_{t-1};\tilde\mu_t(x_t,x_0),\tilde\beta_t\boldsymbol I)
$$
æ ¹æ®è´å¶æ–¯å…¬å¼ï¼Œæœ‰ï¼š
$$
q(x_{t-1}|x_t,x_0) = q(x_{t}|x_{t-1},x_0)\frac{q(x_{t-1},x_0)}{q(x_t,x_0)}\\
$$
å°†ä¸Šå¼ç”¨åˆ†å¸ƒè¡¨ç¤ºï¼ŒåŒæ—¶è¿›è¡Œå±•å¼€
$$
(9)\;âˆexpâ¡(âˆ’\frac{1}{2}(\frac{(x_tâˆ’\sqrt{Î±_t}x_{tâˆ’1})^2}{Î²_t} + \frac{(x_{tâˆ’1}âˆ’\sqrt{Î±_{tâˆ’1}}x_0)^2}{1âˆ’\barÎ±_{tâˆ’1}}âˆ’\frac{x_tâˆ’\sqrt{\barÎ±_t}x_0)^2}{1âˆ’\barÎ±_t}))\\
= expâ¡(âˆ’\frac{1}{2}(\frac{x_t^2âˆ’2\sqrtÎ±_tx_tx_{tâˆ’1}+Î±_tx_{tâˆ’1}^2}{Î²t}+\frac{x_{tâˆ’1}^2âˆ’2\sqrt{\barÎ±_{tâˆ’1}}x_0x_{tâˆ’1}+\barÎ±_{tâˆ’1}x_0^2}{1âˆ’\barÎ±_{tâˆ’1}}âˆ’\frac{(x_tâˆ’\sqrt{\barÎ±_t}x_0)^2}{1âˆ’\barÎ±_t}))\\
=expâ¡(âˆ’\frac{1}{2}((\frac{Î±_t}{Î²_t}+\frac{1}{1âˆ’\barÎ±_{tâˆ’1}})x_{tâˆ’1}^2âˆ’(\frac{2\sqrtÎ±_t}{Î²_t}x_t+\frac{2\barÎ±_{tâˆ’1}}{1âˆ’\barÎ±_{tâˆ’1}}x_0)x_{tâˆ’1}+C(x_t,x_0)))\label{7}
$$

> ==**æ•°å­¦è§£é‡Š**==
>
> * æ ¹æ®å‰å‘è¿‡ç¨‹ï¼Œå¯ä»¥å¾—åˆ°ï¼š
>   $q(x_{t}|x_{t-1},x_0) = \sqrt\alpha_tx_{t-1}+\sqrt{1-\alpha_t}\epsilon âˆ¼N(\sqrt\alpha_tx_{t-1},1-\alpha_t)$
>   $ {q(x_{t-1},x_0)} = \sqrt{\bar\alpha_{t-1}}x_{0}+\sqrt{1-\bar\alpha_{t-1}}\epsilon âˆ¼N(\sqrt{\bar\alpha_{t-1}}x_{0},1-\bar\alpha_{t-1})$
>   $ {q(x_t,x_0)}=\sqrt\alpha_tx_{0}+\sqrt{1-\bar\alpha_{t}}\epsilonâˆ¼N(\sqrt\alpha_tx_{0},1-\bar\alpha_{t})$
>
> * é«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼š $ f(x) = \frac{1}{\sqrt{2\pi}\sigma}exp({-\frac{1}{2}(\frac{x-\mu}{\sigma})^2})$ ï¼Œäºæ˜¯æœ‰ $N(\mu, \sigma^2) \propto exp({-\frac{1}{2}(\frac{x-\mu}{\sigma})^2})$ï¼Œå±•å¼€ååœ¨ $exp$ ä¸­ï¼Œä¹˜æ³•å°±æ˜¯ç›¸åŠ ï¼Œé™¤æ³•å°±æ˜¯ç›¸å‡ã€‚

åˆå› ä¸º  $exp({-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}) = exp(-\frac{1}{2}(\frac{1}{\sigma^2}x^2-\frac{2\mu}{\sigma^2}x+ \frac{\mu^2}{\sigma^2}))$ ï¼Œæ‰€ä»¥æ ¹æ® $\eqref{7}$ å¯ä»¥å¾—åˆ°å…³äº $x_{t-1}$ çš„åˆ†å¸ƒæ–¹å·®å’Œå‡å€¼ï¼š
$$
\tilde\beta_t = \frac{1}{(\frac{Î±_t}{Î²_t}+\frac{1}{1âˆ’\barÎ±_{tâˆ’1}})} = \frac{1âˆ’\barÎ±_{tâˆ’1}}{1âˆ’\barÎ±_{t}} \cdot \beta_t
\\\tilde\mu_t(x_t,x_0) = \frac{\sqrt\alpha_t(1-\bar\alpha_{t-1})}{1-\bar\alpha_{t}}x_t+ \frac{\sqrt{\bar\alpha_{t-1}}\beta_t}{1-\bar\alpha_{t}}x_0\label{8}
$$
ç”±äºå½“å‰çš„å·²çŸ¥æ˜¯ $x_t$ ï¼Œåœ¨å‰å‘è¿‡ç¨‹ä¸­æ¨ç†äº† $x_t$ ä¸ $x_0$ çš„å…³ç³» ï¼Œé‚£ä¹ˆåˆ©ç”¨å…¬å¼ $\eqref{4}$ å°† $x_0$ ç”¨ $x_t$ æ¥è¿‘ä¼¼ï¼Œæœ‰ï¼š
$$
x_0 =\frac{1}{\sqrt{\bar\alpha_t}}(x_t-\sqrt{1-\bar\alpha_t}\epsilon_t)
$$

$$
\tilde\mu_t = \frac{1}{\sqrt\alpha_t}(x_t-\frac{\beta_t}{\sqrt{1-\bar\alpha_t}}\epsilon_t)
$$

==ğŸ§Question==  **How to get $\boldsymbol{\epsilon_t}$ ï¼Ÿ**    ğŸ™Œ*Train a model to predict it.*

### 2.3 Algrithms

#### 2.3.1 Training (Predict the noise)

| Algrithm 1 Training                                          | Note                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1: **repeat**                                                |                                                              |
| 2:     $x_0 âˆ¼ q(x_0)$                                        | $x_0$ ä¸ºåˆ†å¸ƒ $q$ ä¸­éšæœºé‡‡æ ·çš„å›¾åƒï¼ˆæ•°æ®é›†ä¸­å–æ•°æ®ï¼‰          |
| 3:     $t âˆ¼ Uniform(\{1,...,T\})$                            | $ t$ å³æ‰©æ•£æ¬¡æ•°ï¼Œä» $0$ åˆ° $T$ï¼Œå¯¹ä¸åŒçš„å›¾åƒæ˜¯ä¸å›ºå®šçš„       |
| 4:     $\epsilon âˆ¼ N(0, I)$                                  | $\epsilon$ é«˜æ–¯åˆ†å¸ƒ $N(0, I)$ ä¸­éšæœºé‡‡æ ·çš„å™ªå£°ï¼ˆä»å‰å‘è¿‡ç¨‹è·å¾—ï¼‰ |
| 5:     Take gradient descent step on  $\gradient_\theta â€–Ïµâˆ’Ïµ_Î¸(\sqrt{\bar Î±_t}x_0+\sqrt{1âˆ’\bar Î±_t}Ïµ,t)â€–^2 $ | $Ïµ_Î¸$ å³è®­ç»ƒçš„æ¨¡å‹ï¼Œæ‹¬å·å†…æ˜¯è¾“å…¥ï¼šæ—¶é—´ä»¥åŠ $x_t$             |
| 6: **until** converged                                       |                                                              |

#### 2.3.2 Sampling (To get $x_0$) 

| Algrithm 2 Sampling                                          | Note                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1: $x_T âˆ¼ N(0, I)$                                           | $x_T$ é«˜æ–¯åˆ†å¸ƒ $N(0, I)$ ä¸­éšæœºé‡‡æ ·çš„å™ªå£°                    |
| 2: **for** $t = T,...,1 $ **do**                             |                                                              |
| 3:     $z âˆ¼ N(0, I)$ **if** $t>1$ , **else** $z = 0$         | $ t = 1$ å³ $x_0$ æ—¶åˆ»æ²¡æœ‰å™ªå£°ï¼Œå…¶ä»–æ—¶åˆ»éƒ½æœ‰ä»åˆ†å¸ƒä¸­é‡‡æ ·çš„å™ªå£°ï¼ˆé‡å‚æ•°ï¼‰ |
| 4:     $x_{t-1} = \frac{1}{\sqrt\alpha_t}(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t}}\epsilon_\theta(x_t, t)) + \sigma_tz$ |                                                              |
| 5:     **end for**                                           |                                                              |
| 6: **return** $x_0$                                          |                                                              |

## 3. Code

* diffusion model demo
* diffusion in DALLÂ·E 2 ï¼ˆimage generationï¼‰

## References:

[1] Radford A, Kim J W, Hallacy C, et al. Learning transferable visual models from natural language supervision[C]//International Conference on Machine Learning. PMLR, 2021: 8748-8763.
[2] **Ho J, Jain A, Abbeel P. Denoising diffusion probabilistic models[J]. Advances in Neural Information Processing Systems, 2020, 33: 6840-6851.**
[3] https://openai.com/dall-e-2/
[4] https://huggingface.co/spaces/dalle-mini/dalle-mini
[5] https://lilianweng.github.io/posts/2021-07-11-diffusion-models/
[6] https://www.bilibili.com/video/BV1b541197HX/?spm_id_from=333.788&vd_source=7020551ede7e34125c5de7acc9417f8d
[7] https://www.bilibili.com/video/BV1tY4y1N7jg/?spm_id_from=333.788.recommend_more_video.1&vd_source=7020551ede7e34125c5de7acc9417f8d
[8] https://github.com/heejkoo/Awesome-Diffusion-Models
[9] https://www.bilibili.com/video/BV1ad4y1c7vY/?spm_id_from=333.337.search-card.all.click&vd_source=7020551ede7e34125c5de7acc9417f8d

